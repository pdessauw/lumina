services:
  sglang:
    image: ${SGLANG_IMAGE}
    container_name: sglang
    volumes:
      - ${MODEL_DIRPATH}:/data/llms
    restart: always
    environment:
      MODEL_DIRPATH: ${MODEL_DIRPATH}
      MODEL_FNAME: ${MODEL_FNAME}
    entrypoint: python3 -m sglang.launch_server
    command: 
      --model-path /data/llms/${MODEL_FNAME}
      --host 0.0.0.0
      --port 31013
    ulimits:
      memlock: -1
      stack: 67108864
    shm_size: "8gb"
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:31013/health || exit 1"]
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ["0"]
              capabilities: [gpu]
  openwebui:
    image: ${OPENWEBUI_IMAGE}
    container_name: openwebui
    volumes:
      - openwebui:/app/backend/data
    restart: always
    environment:
      - ENV=dev
    depends_on:
      - sglang
  nginx:
    image: ${NGINX_IMAGE}
    container_name: nginx
    restart: always
    ports:
      - "${HTTP_PORT}:80"
      - "${HTTPS_PORT}:443"
    depends_on:
      - openwebui
    environment:
      - HTTPS_PORT=${HTTPS_PORT}
    volumes:
      - nginx_confd:/etc/nginx/conf.d
      - ./nginx/conf.d/openwebui.conf:/etc/nginx/templates/openwebui.conf.template
      - ./nginx/ssl:/etc/ssl/
volumes:
  openwebui:
    name: "openwebui"
  nginx_confd:
    name: "nginx_confd"

